{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 딥러닝의 초기 역사\n",
    "\n",
    "<br>\n",
    "\n",
    "이번 절에서는 ILSVRC 대회를 축으로 최근의 딥러닝 트렌드를 살펴보고자 한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 이미지넷 (ImageNet)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 이미지넷 (ImageNet)\n",
    "\n",
    "<br>\n",
    "\n",
    ": 100만 장이 넘는 이미지를 담고 있는 \"데이터셋\"\n",
    "\n",
    ": [이미지 + 레이블] 로 구성됨\n",
    "\n",
    "<img src = \".\\deep_learning_images\\fig 8-7.png\" height = 70% width = 70% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>ImageNet 데이터셋</span></div>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "### ILSVRC 분류(classification) 대회\n",
    "\n",
    "<br>\n",
    "\n",
    ": 2012년 이후 딥러닝 방식을 차용한 알고리즘이 선두를 차지하는 것을 알 수 있음\n",
    "\n",
    ": 특히, 2012년 AlexNet 모델이 오류율을 크게 낮춤\n",
    "\n",
    ": 2015년 부터는 인간의 인식 능력을 넘어섬\n",
    "\n",
    "<img src = \"https://blog.kakaocdn.net/dn/qTosh/btqEcHOWtQ9/rJH68q6vDvsxgqMAFj9Br1/img.png\" height = 50% width = 50% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>ILSVRC 최우수 알고리즘의 분류 에러율</span></div>\n",
    "    \n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "## VGG\n",
    "\n",
    "<br>\n",
    "\n",
    ": 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN\n",
    "\n",
    ": 16층(VGG 16) 혹은 19층(VGG 19)으로 구성됨\n",
    "\n",
    ": 3x3의 필터를 사용\n",
    "\n",
    ": 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄임\n",
    "\n",
    "<img src = \"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" height = 50% width = 50% align = \"center\">\n",
    "<img src = \"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\" height = 50% width = 50% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>VGG16 구조</span></div>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "## GoogLeNet\n",
    "\n",
    "<br>\n",
    "\n",
    ": \"인셉션 구조\" (세로 방향 깊이 + 가로 방향 깊이)\n",
    "\n",
    "    * 인셉션 구조\n",
    "    : 크기가 다른 필터 및 풀링을 여러 개 적용하여 그 결과를 결합\n",
    "    : GoogLeNet은 인셉션 구조를 하나의 빌딩 블록(구성요소)으로 사용\n",
    "\n",
    "<img src = \"https://i.stack.imgur.com/QUtQb.png \" height = 100% width = 100% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>인셉션 구조</span></div>\n",
    "   \n",
    "<br>\n",
    "\n",
    "\n",
    ": 1x1 크기의 필터를 사용하여 크기를 줄임 → 매개변수 제거와 고속 처리에 기여\n",
    "\n",
    "\n",
    "<img src = \"https://miro.medium.com/max/2800/0*rbWRzjKvoGt9W3Mf.png\" height = 100% width = 100% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>GoogLeNet 구조</span></div>\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "## ResNet (Residual Network)\n",
    "\n",
    "<br>\n",
    "\n",
    ": MS에서 개발한 네트워크\n",
    "\n",
    ": \"스킵 연결(skip connection)\"을 통해 \"층의 깊이에 비례해 성능을 향상\"시킴\n",
    "\n",
    "▶ WHY? 역전파 때, 스킵 연결이 신호 감쇠를 막아주기 때문 (즉, 층을 깊게 할수록 기울기가 작아지는 소실 문제를 방지)\n",
    "\n",
    "▶ BUT, 아직 무조건 층을 깊게 하는데는 한계가 존재\n",
    "\n",
    "    * 스킵 연결\n",
    "    : 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조\n",
    "    \n",
    "<img src = \".\\deep_learning_images\\fig 8-12.png\" height = 30% width = 30% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>스킵 연결의 예</span></div>\n",
    "\n",
    "<br>\n",
    "\n",
    ": 예) VGG 신경망을 기반으로 스킵 연결을 도입하여 층을 깊게 한 구조\n",
    "\n",
    "\n",
    "<img src = \".\\deep_learning_images\\fig 8-13.png\" height = 70% width = 70% align = \"center\">\n",
    "<div style=\"text-align: center\"><span style = 'color : silver; font-size : 13px'>ResNet의 예</span></div>\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "## 전이 학습 (transfer learning)\n",
    "\n",
    "<br>\n",
    "\n",
    ": 학습된 가중치를 다른 신경망에 복사한 다음, 그 상태로 재학습(fine tuning)을 수행하는 것\n",
    "\n",
    ": 보유한 데이터 셋이 적을 때 유용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
